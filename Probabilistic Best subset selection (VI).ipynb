{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import scipy\n",
    "import time\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "tfd = tfp.distributions\n",
    "Normal = tfd.MultivariateNormalFullCovariance\n",
    "slim=tf.contrib.slim\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "import argparse\n",
    "import multiprocessing as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--grad', '-g', type=str, default='u2g', \\\n",
    "                    help='reinforce, arm, u2g')\n",
    "parser.add_argument('--lmbd',  type=float, default=10., help='lmbd')\n",
    "parser.add_argument('--lr', '-l', type=float, default=0.01, help='lr')\n",
    "\n",
    "parser.add_argument('--name', '-n', default='exp2_vb', help='exp,model name')\n",
    "parser.add_argument('--sigma',  type=float, default=1.414, \\\n",
    "                    help='variance of epsilon, 1.195 or 1.414 for SNR=7 or 5')\n",
    "parser.add_argument('--sigma_beta',  type=float, default=1.0, \\\n",
    "                    help='variance of slab prior')\n",
    "parser.add_argument('--N', type=int, default=100, help='number of data')\n",
    "parser.add_argument('--P', '-b', type=int, default=1000, help='dimension size')\n",
    "parser.add_argument('--K', type=int, default=10, help='number of MC sample')\n",
    "\n",
    "parser.add_argument('--iter',  type=int, default=10000, help='iter')\n",
    "parser.add_argument('--N_test', type=int, default=10, \\\n",
    "                    help='number of repeated experiment')\n",
    "\n",
    "#args = parser.parse_args()\n",
    "args, unknown = parser.parse_known_args()  \n",
    "eps = 1e-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bernoulli_loglikelihood(b, log_alpha):\n",
    "    return b * (-tf.nn.softplus(-log_alpha)) + (1 - b) * \\\n",
    "                        (-log_alpha - tf.nn.softplus(-log_alpha))\n",
    "\n",
    "def log_p_yz(E, x, y):\n",
    "    def ff(E, x, y, sigma, sigma_beta):\n",
    "        '''\n",
    "        compute covariance matrix when active set is not empty\n",
    "        '''\n",
    "        idx = tf.squeeze(tf.where(tf.not_equal(E,0)))       \n",
    "        X1 = tf.gather(x,idx,axis=1)\n",
    "        X1 = tf.reshape(X1,[args.N,-1])\n",
    "        V0 = tf.matmul(X1, tf.transpose(X1))\n",
    "        cov = (sigma_beta**2)*V0 + (sigma**2) * tf.eye(args.N)\n",
    "        return cov\n",
    "    cov = tf.cond(tf.greater(tf.reduce_sum(E), 1e-2), lambda:ff(E, x, y,  \\\n",
    "                  args.sigma, args.sigma_beta),\\\n",
    "                  lambda:(args.sigma**2) * tf.eye(args.N))\n",
    "    mean = tf.zeros(args.N)\n",
    "    mvn = Normal(mean, cov)\n",
    "    return mvn.log_prob(y)\n",
    "\n",
    "\n",
    "def data_gen(N, P, sigma,seed=1):\n",
    "    beta_true = np.array([1.]*10+[0.]*(P-10))  \n",
    "    def cov(P, rho = 0.):\n",
    "        V = np.empty([P,P])\n",
    "        for i in range(P):\n",
    "            for j in range(i):\n",
    "                V[i,j] = np.power(rho, np.abs(i-j))\n",
    "                V[j,i] = V[i,j]\n",
    "        for i in range(P):\n",
    "            V[i,i] = 1    \n",
    "        return V\n",
    "    V = cov(P)\n",
    "    M = np.array([0]*P)\n",
    "    ############\n",
    "    np.random.seed(seed)\n",
    "    ############\n",
    "    X = np.random.multivariate_normal(mean=M, cov=V, size = N)\n",
    "    noise = np.random.normal(scale = sigma, size = N)\n",
    "    Y = np.matmul(X, beta_true) + noise\n",
    "    Y = Y.astype(np.float32) \n",
    "    X = X.astype(np.float32) \n",
    "    return X, Y, V, beta_true\n",
    "\n",
    "def main(ss): \n",
    "    X,Y,COV,beta_true = data_gen(args.N,args.P,args.sigma,seed=ss)    \n",
    "    z_true = (beta_true>0)\n",
    "    SNR = np.matmul(np.matmul(beta_true, COV),beta_true) / (args.sigma**2)  \n",
    "\n",
    "    tf.reset_default_graph(); \n",
    "     \n",
    "    x = tf.placeholder(tf.float32,[args.N, args.P],name='data_x')  \n",
    "    y = tf.placeholder(tf.float32,[args.N],name='data_y')   \n",
    "    \n",
    "    phi = tf.get_variable(\"phi\", dtype=tf.float32, \\\n",
    "                          initializer=tf.random.normal([args.P]))\n",
    "    prob = tf.sigmoid(phi)\n",
    "    \n",
    "    def fun(E):\n",
    "        logit_pi = - args.lmbd/(2*args.sigma**2)    \n",
    "        log_p_y_given_z = log_p_yz(E, x, y)\n",
    "        log_p_z = tf.reduce_sum(bernoulli_loglikelihood(E, logit_pi))\n",
    "        log_q_z = tf.reduce_sum(bernoulli_loglikelihood(E, phi))\n",
    "        return log_p_z+log_p_y_given_z-log_q_z\n",
    "        \n",
    "    u_noise = tf.random_uniform(shape=[args.K,args.P],maxval=1.0)  #K*P\n",
    "    E1 = tf.cast(u_noise>tf.sigmoid(-phi),tf.float32)\n",
    "    E2 = tf.cast(u_noise<tf.sigmoid(phi),tf.float32)   \n",
    "    if args.grad == 'arm' or 'u2g':\n",
    "        Fun1 = tf.map_fn(fun, E1)       \n",
    "        Fun2 = tf.map_fn(fun, E2)\n",
    "        F_term = Fun1 - Fun2\n",
    "        elbo = tf.reduce_mean(Fun2)\n",
    "    elif args.grad == 'reinforce' :\n",
    "        F_term = tf.map_fn(fun, E2)\n",
    "        elbo = tf.reduce_mean(Fun2)\n",
    "    else:\n",
    "        raise ValueError('No grad defined')\n",
    "    if len(np.shape(F_term))<2:\n",
    "        F_term = F_term[:,None]  #K*1\n",
    "    \n",
    "    if args.grad == 'arm':\n",
    "        G = F_term*(u_noise - 0.5)\n",
    "        phi_tile = tf.tile(phi[None,:], [args.K,1]) #K*P  \n",
    "        mask = tf.to_float(tf.abs(E1 - E2))\n",
    "        G_mask = G * mask\n",
    "        grad = tf.reduce_mean(G_mask,axis=0) \n",
    "    elif args.grad == 'u2g':\n",
    "        phi_tile = tf.tile(phi[None,:], [args.K,1])\n",
    "        current_prob = tf.sigmoid(phi_tile)\n",
    "        G = F_term * tf.to_float(E1 - E2) * \\\n",
    "                        tf.maximum(current_prob,1-current_prob)/2.0\n",
    "        grad = tf.reduce_mean(G,axis=0) \n",
    "    elif args.grad == 'reinforce':\n",
    "        phi_tile = tf.tile(phi[None,:], [args.K,1]) \n",
    "        current_prob = tf.sigmoid(phi_tile)\n",
    "        G = F_term * (tf.to_float(E2)-current_prob)\n",
    "        grad = tf.reduce_mean(G,axis=0) \n",
    "                    \n",
    "    train_opt = tf.train.GradientDescentOptimizer(args.lr)\n",
    "    \n",
    "    gradvars = zip([-grad], [phi])\n",
    "    train_op = train_opt.apply_gradients(gradvars)\n",
    "  \n",
    "    init_op=tf.global_variables_initializer()\n",
    "    \n",
    "    sess=tf.InteractiveSession()\n",
    "    sess.run(init_op)    \n",
    "    cost_r = []; entropy_r=[]; \n",
    "    \n",
    "    start = time.time()\n",
    "    for i in range(args.iter):   \n",
    "        _,cost = sess.run([train_op, elbo],{x:X, y:Y})\n",
    "        cost_r.append(cost)  \n",
    "        probz = np.squeeze(sess.run(prob))           \n",
    "        entropy = np.sort(- probz * np.log(probz + eps))\n",
    "        entropy_r.append(np.mean(entropy))\n",
    "        if np.mean(entropy[-args.P//100:])<0.2:\n",
    "            break      \n",
    "    \n",
    "    probability = np.squeeze(sess.run(prob))\n",
    "    z_hat = np.array(probability>0.5).astype(np.int32)  \n",
    "    beta_hat = np.zeros([args.P])\n",
    "    if sum(np.abs(z_hat))>eps:\n",
    "        X1 = np.take(X, np.squeeze(np.where(z_hat != 0)), axis=1)\n",
    "        if sum(np.abs(z_hat)) == 1:\n",
    "            X1 = X1[:,None]\n",
    "        beta_hat0 = scipy.linalg.lstsq(X1, Y,cond=eps, lapack_driver= 'gelsy')[0]\n",
    "        beta_hat[np.where(z_hat != 0)] = beta_hat0    \n",
    "    \n",
    "    #Evaluation metric\n",
    "    ols_results = sm.OLS(Y, X).fit()\n",
    "    beta_ols = ols_results.params\n",
    "    \n",
    "    TP = np.sum(z_true * z_hat ) \n",
    "    FP = np.sum((1-z_true) * z_hat) \n",
    "    FN = np.sum(z_true * (1-z_hat)) \n",
    "    \n",
    "    prec = TP/(TP + FP + + eps)   \n",
    "    rec = TP/(TP + FN + eps)\n",
    "    F1 = 2 * prec * rec / (prec + rec + eps)\n",
    "         \n",
    "    RTE_ols = 1 + np.matmul(np.matmul((beta_true-beta_ols), COV),\\\n",
    "                            (beta_true-beta_ols)) / (args.sigma**2)    \n",
    "    RTE_grad = 1 + np.squeeze(np.matmul(np.matmul((beta_hat-beta_true), COV),\\\n",
    "                             (beta_hat-beta_true).T) / (args.sigma**2))\n",
    "    SNR = np.matmul(np.matmul(beta_true, COV),beta_true) / (args.sigma**2)       \n",
    "    \n",
    "\n",
    "    print('Trial-'+str(ss),': prec =', round(prec,2), 'rec =', round(rec,2), \\\n",
    "           'Iter =', i)    \n",
    "    \n",
    "    corr = np.sum((1-z_true) * (1-z_hat))\n",
    "    incorr = FN\n",
    "    duration = time.time()-start\n",
    "    all_ = [prec, rec, F1, corr, incorr, RTE_ols, \\\n",
    "            RTE_grad, SNR, duration, args.lmbd]\n",
    "    sess.close()\n",
    "    return(all_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial-1 : prec = 1.0 rec = 1.0 Iter = 4868\n",
      "Trial-3 : prec = 0.75 rec = 0.9 Iter = 9999\n",
      "Trial-0 : prec = 1.0 rec = 1.0 Iter = 9999\n",
      "Trial-4 : prec = 0.67 rec = 0.6 Iter = 9999\n",
      "Trial-2 : prec = 1.0 rec = 1.0 Iter = 9999\n",
      "Trial-6 : prec = 1.0 rec = 1.0 Iter = 9999\n",
      "Trial-5 : prec = 1.0 rec = 1.0 Iter = 9999\n",
      "Trial-7 : prec = 0.91 rec = 1.0 Iter = 8925\n",
      "Trial-9 : prec = 1.0 rec = 1.0 Iter = 9999\n",
      "Trial-8 : prec = 1.0 rec = 1.0 Iter = 9999\n",
      "Time per trial is 22.6846678019\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    start = time.time()\n",
    "    pool = mp.Pool(mp.cpu_count()-1)\n",
    "    results = pool.map(main, [i for i in range(args.N_test)])\n",
    "    print('Time per trial is',(time.time()-start)/args.N_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
